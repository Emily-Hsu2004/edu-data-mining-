# 資料處理與資料清理
## 資料科學工作流程(workflow)

```mermaid
graph LR
A(取得資料) -->B(資料前處理)
    B --> C(模型訓練)
    C --> D(模型評估)
    D --> E(決策應用)
```

分析 -> 處理 -> 分析 -> 處理 ...

- **取得資料**：資料獲取（Data Acquisition）、爬蟲（Data Crawling）、資料庫管理（Database Management）、資料倉儲（Data Warehousing）。
- **資料前處理**
- **模型訓練與評估**：探索性分析（EDA）→ 資料探勘 / 機器學習（Data Mining / ML）。可以把探索性分析視為是⼀種前期的觀察，在經由資料探勘進⾏近⼀步地挖掘。
---
## 資料前處理
- **定義**：將原始資料處理成適合分析和建模的格式。
- **ETL（Extract-Transform-Load）**：抽取(extract)、轉換(transform)、載入(load)的過程，應用於 BI、Data Pipeline、資料倉儲。
- **Data Pipeline**：指透過 *自動化* 程序處理資料的流程，是 MLOps 前面一段自動化流程。
### 為什麼要前處理資料？
在實務上，資料往往並不是如此美好與乾淨，可能遇到以下狀況：
#### 資料缺失（Missing Data/Incomplete）
可能因為系統錯誤、人為因素產生。
**類型**：
1. 完全隨機缺失值(missing completely at random)
2. 隨機缺失值(missing at random)
3. ⾮隨機遺漏(not missing at random)
> NaN vs None
> NaN：應該要有卻沒有
> None：沒有東西

**處理方式**：
1. 刪除缺失值 *（適用於少量遺漏或太多遺漏）*。
2. 人工填補 *（成本高）*
3. 常數（0、-1、Unknown）*（資料分布不明顯）*。
4. 統計方法填補（平均數、中位數、眾數、內差、回歸） *（建議首選嘗試）*。
	- 類似資料的統計值 *（資料特性明確的時候）*
5. 機器學習填補（預測） *（KNN、分群）*。

- **資料雜訊（Noise）**：
  - 可能包含錯誤值、亂碼、特殊符號。
  
- **資料型態不一致（Inconsistent Data）**：
  - 可能因不同來源格式不一。

*適合模型的資料* ：模型可以學習（Learniable）的資料指的是能夠經由數學模型存取的資料格式，也就是數學上的「向量/矩陣」，在程式當中通常以「Vector/DataFrame」來存放。

---

## 資料型態與編碼

| 使用者 | 月收入<br>(數字) | 年紀<br>(數字) | 性別<br>(字串) | 購買遊戲<br>(布林) | 購買精品<br>(布林) |
| :---: | :---: | :---: | :---: | :---: | :---: |
| 1 | 32000 | 23 | 女 | 是 | 否 |
| 2 | 48000 | 32 | 男 | 是 | 否 |
| 3 | 30000 | 23 | 男 | 是 | 否 |
| 4 | 68000 | 49 | 男 | 是 | 否 |
| 5 | 79000 | 54 | 女 | 否 | 是 |
| 6 | 66000 | 48 | 男 | 是 | 否 |

- **類別型（Categorical Data）**：
  - **有序類別**：Label Encoding（例如年齡：少年=1，中年=2，老年=3）。
  - **無序類別**：One-Hot Encoding（例如水果：蘋果= [1,0,0]，橘子= [0,1,0]，西瓜= [0,0,1]）。
- **數值型（Numerical Data）**：
  - 連續值（Continuous）
  - 離散值（Discrete） → 可能轉成類別再做 One-Hot Encoding。

| 使用者 | 名字 | 年齡 | 喜歡吃的水果 |
| :---: | :---: | :---: | :---: |
| 1 | 小華 | 少年 | 蘋果 |
| 2 | 小明 | 少年 | 蘋果 |
| 3 | 張三 | 中年 | 蘋果 |
| 4 | 小白 | 老年 | 橘子 |
| 5 | 李四 | 老年 | 西瓜 |
| 6 | 小花 | 中年 | 橘子 |

| 使用者 | 名字 | 年齡 | 喜歡吃的水果 |
| :---: | :---: | :---: | :---: |
| 1 | 小華 | 1 | 蘋果 |
| 2 | 小明 | 1 | 蘋果 |
| 3 | 張三 | 2 | 蘋果 |
| 4 | 小白 | 3 | 橘子 |
| 5 | 李四 | 3 | 西瓜 |
| 6 | 小花 | 2 | 橘子 |

| 使用者 | 名字 | 年齡 | 喜歡吃蘋果 | 喜歡吃橘子 | 喜歡吃西瓜 |
| :---: | :---: | :---: | :---: | :---: | :---: |
| 1 | 小華 | 1 | 1 | 0 | 0 |
| 2 | 小明 | 1 | 1 | 0 | 0 |
| 3 | 張三 | 2 | 1 | 0 | 0 |
| 4 | 小白 | 3 | 0 | 1 | 0 |
| 5 | 李四 | 3 | 0 | 0 | 1 |
| 6 | 小花 | 2 | 0 | 1 | 0 |

---

## 特徵工程（Feature Engineering）
**目的**：模型的準確率與表現性能可以達到最優（或者接近最佳性能）。
- 欄位 Field = 特徵 Feature = 解釋變數 = X
- ⽬標 Target = 標籤 Label = 反應變數 = Y
> 將原始資料調整成*適合模型* 的樣⼦
###  特徵轉換
- **類別轉數值**：Label Encoding、One-Hot Encoding。
- **數據標準化（Feature Scaling）**：
  1. **標準化（Standardization）**：將資料轉換為均值 0、標準差 1。$x’= \dfrac{x-\min(x)}{\max(x)-\min(x)}\ \text{or}\ \dfrac{x-\text{average}(x)}{\max(x)-\min(x)}$
  2. **正規化（Normalization）**：將數據縮放至 0-1 區間。$z=\dfrac{x-\mu}{\sigma}$
  3. **Log 轉換（Logization）**：縮小數據範圍、解決偏態問題。

- **連續轉離散（Binning）**：
  - 例如年齡區間（0-18、19-30、31-50、50+）。
### 特徵操作
**Feature Construction** *根據 domain 設計欄位*
特徵構建指的是從原有的特徵中，⼈⼯地創造出新的有意義特徵，通常⽤來解決⼀般的線性模型沒辦法學到⾮線性特徵的問題。 

**Feature Interaction** *連續型欄位合併*
⽬的為透過不同算法操作，由現有特徵組合出新的潛在有效特徵。假設有 A 和 B 兩個 continuous 特徵，可以⽤ A + B、A - B、A * B或 A / B 之類的⽅式建⽴新的特徵。

**Feature Combination** *離散型欄位合併*
主要是針對類別特徵，把兩個以上的特徵透過某種⽅式結合在⼀起，變成新的特徵。通常⽤來解決⼀般的線性模型沒辦法學到⾮線性特徵的問題。

### 特徵選擇（Feature Selection）
> 挑出重要的
- **方法**：
  - **Filter Method**：根據統計指標（如相關係數）篩選。
  - **Wrapper Method**：利用機器學習測試不同組合的特徵。
  - **Embedded Method**：模型內建特徵選擇（如 Lasso 回歸）。

### 特徵提取（Feature Extraction）
> 把部分重疊特徵重新組裝
- **目標**：降低維度，同時保留資訊。
- **方法**：
  - PCA（主成分分析）。
  - Autoencoder（深度學習降維）。
  - LDA（線性判別分析）。

---

## 異常值（Outlier）處理
- **定義**：與其他數據明顯不同的數據點，可能來自測量誤差或特殊情況。
> Outlier 代表⾮典型（極少量）的資料，不⼀定是錯誤的
- **偵測方式**：
  - 統計方法（如標準差超過 2 倍）。
  - 分群演算法
  - 孤⽴森林/隨機分割森林。

- **處理策略**：同Missing Value 的處理策略
  - 直接刪除（適用於明顯錯誤）。
  - ⼈⼯取代。
  - 常數（0/-1）或通⽤值（unknown）。
  - 用統計值取代（如中位數）。
  - 機器學習預測補值。

---

## 不平衡資料（Unbalanced Data）處理
- **例子**：詐欺檢測、疾病診斷（少數類別樣本極少）。
- **解決方案**：
  - **過採樣（Oversampling）**：增加少數類別樣本。
  - **欠採樣（Undersampling）**：減少多數類別樣本。
